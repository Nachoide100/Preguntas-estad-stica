# ğŸ“Š Laboratorio de EstadÃ­stica: Conceptos y Casos PrÃ¡cticos

Este repositorio es una base de conocimientos dedicada a los fundamentos estadÃ­sticos necesarios para el anÃ¡lisis de datos riguroso. AquÃ­ documento desde conceptos bÃ¡sicos hasta la resoluciÃ³n de dilemas complejos en experimentaciÃ³n y pruebas de hipÃ³tesis.

---

### ğŸ—ºï¸ NavegaciÃ³n RÃ¡pida

[![](https://img.shields.io/badge/Nivel-FÃ¡cil-brightgreen?style=for-the-badge)](#-nivel-fÃ¡cil-fundamentos)
[![](https://img.shields.io/badge/Nivel-Intermedio-yellow?style=for-the-badge)](#-nivel-intermedio-aplicaciÃ³n)
[![](https://img.shields.io/badge/Nivel-DifÃ­cil-red?style=for-the-badge)](#-nivel-difÃ­cil-avanzado)

---

## ğŸŸ¢ Nivel: FÃ¡cil (Fundamentos)

### â“ Â¿QuÃ© es el Teorema del LÃ­mite Central y por quÃ© es Ãºtil?
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  El **Teorema del LÃ­mite Central (TLC)** sostiene que si extraemos muestras de una poblaciÃ³n un gran nÃºmero de veces, la distribuciÃ³n de las medias de dichas muestras tendrÃ¡ una forma cercana a la **normal**, independientemente de si la distribuciÃ³n original lo es.

  **Utilidad principal:**
  * **Inferencia estadÃ­stica:** Permite tratar a los promedios de las muestras como si tuvieran una distribuciÃ³n normal, lo que es vital para realizar estimaciones y pruebas de hipÃ³tesis sin conocer la distribuciÃ³n real de la poblaciÃ³n.
  
  
</details>

### â“ Â¿CÃ³mo explicarÃ­as los Intervalos de Confianza a una audiencia no tÃ©cnica?
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  Imagina que quieres saber el peso promedio de todos los osos de un parque nacional. Como es imposible pesarlos a todos, pesas a unos pocos (muestra) y calculas el promedio. Ese nÃºmero es solo una estimaciÃ³n.
  
  Un **Intervalo de Confianza** (ej. 95%) indica que nuestro mÃ©todo es fiable: si repitiÃ©ramos el experimento muchas veces, el 95% de los rangos calculados contendrÃ­an el peso real de todos los osos. Cuanto mÃ¡s estrecho es el rango, mÃ¡s precisa es nuestra estimaciÃ³n y menor la incertidumbre.
</details>

### â“ Compara la Covarianza y la CorrelaciÃ³n.
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  | CaracterÃ­stica | Covarianza | CorrelaciÃ³n |
  | :--- | :--- | :--- |
  | **Â¿QuÃ© mide?** | La direcciÃ³n de la relaciÃ³n. | La direcciÃ³n y la **fuerza**. |
  | **Escala** | Sin lÃ­mites (cualquier nÃºmero). | Estrictamente entre **-1 y +1**. |
  | **Unidades** | Depende de las variables (kg x m). | Sin unidades (nÃºmero puro). |
  | **Utilidad** | CÃ¡lculos matemÃ¡ticos internos. | EstimaciÃ³n visual de la relaciÃ³n. |

  
</details>

---

## ğŸŸ¡ Nivel: Intermedio (AplicaciÃ³n)

### â“ Â¿QuÃ© es un Z-test y cuÃ¡ndo usarlo frente a un t-test?
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  Ambos sirven para saber si un estadÃ­stico es significativamente distinto de lo esperado.
  * **Z-test:** Se usa con muestras grandes (>30) o cuando conocemos la varianza de la poblaciÃ³n.
  * **t-test:** Se usa con muestras pequeÃ±as o cuando estimamos la varianza de la poblaciÃ³n a partir de la muestra. La distribuciÃ³n *t* tiene "colas mÃ¡s gruesas" para admitir mayor probabilidad de valores extremos por azar.
</details>

### â“ Â¿CuÃ¡les son los peligros comunes en un Test A/B?
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  1. **Errores Tipo I y II:** Falsos positivos y falsos negativos.
  2. **Pruebas mÃºltiples:** Hacer muchas pruebas simultÃ¡neas aumenta la probabilidad de hallar un falso positivo por puro azar.
  3. **Calidad de datos:** Meter mÃ¡s datos no siempre ayuda; si son irrelevantes, generan ruido y resultados contraproducentes.
</details>

### â“ Describe los Errores Tipo I y Tipo II.
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  * **Tipo I (Falso Positivo):** Rechazar la hipÃ³tesis nula cuando es verdadera (ej. decir que alguien tiene cÃ¡ncer cuando estÃ¡ sano).
  * **Tipo II (Falso Negativo):** No rechazar la nula cuando es falsa (ej. decir que alguien estÃ¡ sano cuando estÃ¡ enfermo).
  
  Existe una **relaciÃ³n inversa**: al intentar reducir uno, solemos aumentar el otro. La gravedad depende del contexto (seguridad vs. medicina).

  
</details>

---

## ğŸ”´ Nivel: DifÃ­cil (Avanzado)

### â“ Caso PrÃ¡ctico: 10 caras seguidas en una moneda. Â¿Es justa?
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  * **HipÃ³tesis Nula ($H_0$):** La moneda es justa (50% probabilidad). Cualquier resultado es puro azar.
  * **P-value:** Probabilidad de obtener 10 caras seguidas por suerte si la moneda fuera justa.
  * **CÃ¡lculo:** $0.5^{10} \approx 0.001$.
  * **ConclusiÃ³n:** Como $0.001 < 0.05$ (alfa comÃºn), tenemos evidencia fuerte para **rechazar la $H_0$**. Es extremadamente improbable que la moneda sea normal.
</details>

### â“ Explica el trasfondo estadÃ­stico del "Poder" (Statistical Power).
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  El poder es la capacidad de una prueba para detectar un efecto real (probabilidad de rechazar $H_0$ cuando es falsa). EstÃ¡ ligado al Error Tipo II.
  
  **Factores que lo afectan:**
  1. **TamaÃ±o de muestra:** A mÃ¡s datos, mÃ¡s poder.
  2. **TamaÃ±o del efecto:** Es mÃ¡s fÃ¡cil detectar cambios grandes que pequeÃ±os.
  3. **Nivel de significaciÃ³n:** El umbral establecido (alfa).
  
  Generalmente se busca un poder del **80%**. Se usa para calcular cuÃ¡ntos datos necesitamos *antes* de empezar un experimento.
</details>

### â“ Consideraciones al comprobar cientos de hipÃ³tesis (MÃºltiples t-tests).
<details>
  <summary><b>Ver Respuesta ğŸ”‘</b></summary>

  Al hacer cientos de pruebas, el riesgo de error tipo I se acumula (Data Snooping). Si "torturas" los datos lo suficiente, algo saldrÃ¡ por azar.
  
  **Medidas correctivas:**
  * **CorrecciÃ³n de Bonferroni:** Dividir el nivel de error (alfa) por el nÃºmero de pruebas.
  * **Holdout Set:** Reservar datos nuevos para validar los hallazgos tras la exploraciÃ³n inicial.
</details>

---
<p align="right">(<a href="#-laboratorio-de-estadÃ­stica-conceptos-y-casos-prÃ¡cticos">Volver arriba â¬†ï¸</a>)</p>
