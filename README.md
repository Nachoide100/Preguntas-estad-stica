# üìä Estad√≠stica

Repositorio de conceptos fundamentales y avanzados de estad√≠stica para el an√°lisis de datos. He intentado responde lo mejor posible a las preguntas, seg√∫n entiendo yo los conceptos y sus aplicaciones. Como siempre, si alguien no est√° de acuerdo en alguna respuesta, comunicadlo!

### üó∫Ô∏è Navegaci√≥n R√°pida

[![](https://img.shields.io/badge/Nivel-F√°cil-brightgreen?style=for-the-badge)](#-nivel-f√°cil)
[![](https://img.shields.io/badge/Nivel-Intermedio-yellow?style=for-the-badge)](#-nivel-intermedio)
[![](https://img.shields.io/badge/Nivel-Dif√≠cil-red?style=for-the-badge)](#-nivel-dif√≠cil)

---

## üü¢ Nivel: F√°cil

### üìñ Explica el Teorema del L√≠mite Central. ¬øPor qu√© es √∫til?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  El teorema del l√≠mite central sostiene que si extraemos muestras de la poblaci√≥n un gran n√∫mero de veces, la distribuci√≥n de las medias de dichas muestras tendr√° una forma cercana a la normal, independientemente de si la distribuci√≥n original lo es.
  
  

  Entre sus principales utilidades destacan:
  * **Facilita la inferencia estad√≠stica** ‚Üí permite tratar a los promedios de las muestras como si tuvieran una distribuci√≥n normal, incluso si no conocemos la distribuci√≥n real de la poblaci√≥n, lo que es vital para realizar estimaciones y pruebas de hip√≥tesis.
</details>

### üìñ ¬øC√≥mo explicar√≠as los intervalos de confianza a una audiencia no t√©cnica?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  Imaginamos que queremos saber el peso promedio de todos los osos de un parque nacional, pero es imposible pesarlos a todos. Para resolverlo, pesamos a unos pocos (muestra) y calculamos el promedio. Sin embargo, sabemos que ese n√∫mero no es exacto para toda la poblaci√≥n, puesto que es solo una estimaci√≥n. Aqu√≠ es donde entran los intervalos de confianza.
  
  El nivel de confianza (95% por ejemplo) indica que nuestro m√©todo es confiable: si repiti√©ramos el experimento muchas veces y calcul√°ramos un nuevo intervalo cada vez, el 95% de esos intervalos contendr√≠an el valor real.
  
  El nivel de confianza se determina por un margen de error establecido con anterioridad al experimento. Cuanto m√°s estrecho se hace el umbral, m√°s precisa se hace la estimaci√≥n, puesto que implica una menor incertidumbre (puedo asegurar gracias a la calidad de mis datos que el valor real estar√° dentro de un rango m√°s peque√±o).
</details>

### üìñ Explica la covarianza y la correlaci√≥n y comp√°ralas.
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  La covarianza es una medida que nos indica si dos variables se mueven en la misma direcci√≥n (si una aumenta la otra tambi√©n y viceversa). Una covarianza positiva ser√° la relaci√≥n entre el peso y la altura (por lo general, si alguien es m√°s alto, tambi√©n tiende a pesar m√°s).
  
  La covarianza tiene el problema de que depende totalmente de las unidades de medida. Si medimos la altura en metros o en cent√≠metros, el n√∫mero de la covarianza cambiar√° dr√°sticamente, lo que hace que sea muy dif√≠cil saber si una relaci√≥n es ‚Äúfuerte‚Äù o ‚Äúd√©bil‚Äù.
  
  Ah√≠ es donde entra la correlaci√≥n. La correlaci√≥n es b√°sicamente una covarianza estandarizada, que podemos utilizar para comparar cualquier variable con una escala fija entre 1 y -1. Adem√°s, nos indica qu√© tan estrecha es la relaci√≥n entre las variables, cuanto m√°s cerca se encuentre el valor de 1 y -1.

  

  | Caracter√≠stica | Covarianza | Correlaci√≥n |
  | :--- | :--- | :--- |
  | **¬øQu√© mide?** | La direcci√≥n de la relaci√≥n (si suben o bajan juntas). | La direcci√≥n y la fuerza de la relaci√≥n. |
  | **Escala** | No tiene l√≠mites (puede ser cualquier n√∫mero). | Limitada estrictamente entre -1 y +1. |
  | **Unidades** | Depende de las unidades de las variables (kilos x metros). | No tiene unidades; es un n√∫mero puro. |
  | **Utilidad** | √ötil para c√°lculos matem√°ticos internos en modelos complejos. | La mejor t√©cnica para estimar visualmente qu√© tan relacionadas est√°n dos cosas. |
</details>

### üìñ ¬øCu√°les son algunos de los peligros / dificultades comunes en el test A/B?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  Los principales peligros y dificultades del test estad√≠stico son los siguientes:
  * **Errores del Tipo I y Tipo II:** cometer un falso positivo que ocurre cuando se rechaza la hip√≥tesis nula (se cree que hay un efecto) a pesar de que la conjetura es falsa. Cometer un falso negativo, que sucede cuando la conjetura es v√°lida, pero no se logra rechazar la hip√≥tesis nula.
  * **Problema de las pruebas m√∫ltiples:** al realizar muchas pruebas de hip√≥tesis simult√°neas, la probabilidad de obtener al menos un falso positivo aumenta dr√°sticamente.
  * **Calidad y relevancia de los datos:** agregar grandes cantidades de datos no siempre mejora la precisi√≥n, ya que si los datos de entrada son irrelevantes, pueden ser contraproducentes para alcanzar el resultado deseado. Es esencial realizar una selecci√≥n de caracter√≠sticas para identificar las variables que realmente contribuyen a la hip√≥tesis.
</details>

### üìñ Describe qu√© son los errores Tipo I y Tipo II y la relaci√≥n entre ellos.
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  El error Tipo I ocurre cuando rechazamos la hip√≥tesis nula a pesar de que es verdadera. Un ejemplo cotidiano ser√≠a por ejemplo someter a alguien a una prueba de c√°ncer y que el resultado sea positivo, cuando el paciente no tiene la enfermedad.
  
  El error Tipo II sucede al contrario, cuando la hip√≥tesis nula es falsa pero no conseguimos rechazarla. Ser√≠a concluir que un paciente est√° sano cuando en realidad s√≠ tiene la enfermedad.
  
  

  Entre ellos existe una relaci√≥n inversa, lo que significa que si intentamos reducir la probabilidad de cometer uno, generalmente aumentamos la probabilidad del otro: si ajustamos la prueba para que sea muy sensible (no perdernos ning√∫n caso real), es m√°s probable que cometamos errores de tipo I, mientras que si hacemos la prueba muy estricta, ser√° m√°s probable que cometamos errores de tipo II.
  
  De todas formas, la gravedad de cada error depende del contexto en el que apliquemos la prueba. En una prueba de seguridad en aeropuertos, preferimos un error de tipo I (revisar una maleta de m√°s) que un error de tipo II (dejar pasar algo peligroso). Sin embargo, en el caso de una cirug√≠a de riesgo, preferimos evitar el error tipo I (operar a alguien que no lo necesita).
</details>

### üìñ ¬øQu√© es un Z-test y cu√°ndo lo usar√≠amos frente a un t-test?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  Un Z-test es una prueba estad√≠stica que se utiliza para saber si un estad√≠stico de un grupo de datos es significativamente distinto de lo que se esperaba o de otro grupo, bas√°ndose en la distribuci√≥n normal.
  
  **¬øCu√°ndo merece la pena usarlo?** Se utiliza cuando el tama√±o de la muestra es grande (> 30 para poder aplicar el Teorema del L√≠mite Central) o cuando conocemos la varianza o desviaci√≥n est√°ndar de toda la poblaci√≥n. En cambio, usar el t-test ser√° √∫til cuando el grupo de datos es peque√±o o cuando tenemos que estimar la varianza de la poblaci√≥n a partir de una muestra.
  
  Como consecuencia de esto, la distribuci√≥n utilizada en el t-test tiene las ‚Äúcolas m√°s gruesas‚Äù (student‚Äôs t-distribution) puesto que al no conocer la varianza de la poblaci√≥n admitimos una mayor probabilidad de observar valores extremos por puro azar.
  ![Distribuciones](https://github.com/Nachoide100/Preguntas-estad-stica/blob/e1939096bbe27b6ead10f155c22b4d06a21108ee/visualizations/Captura%20de%20pantalla%202026-02-03%20192122.png)

  La distribuci√≥n roja ser√≠a la t - student. Conforme la n aumentase, esta ser ir√≠a pareciendo a la distribuci√≥n normal. 
</details>

### üìñ Imagina que tiras una moneda 10 veces y solo observas caras, ¬øcu√°l ser√≠a tu hip√≥tesis nula y el p-value para comprobar si la moneda est√° trucada o no?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  La hip√≥tesis nula es la suposici√≥n b√°sica de que cualquier resultado que veamos se debe simplemente al azar, por lo que en nuestro caso ser√≠a que la moneda es justa y que no est√° trucada. Bajo esta suposici√≥n, esperar√≠amos que la probabilidad de obtener cara en cada lanzamiento fuera del 50%.
  
  Por otro lado, el p-value se√±ala c√≥mo de probable es que el resultado que observamos (10 caras seguidas) haya ocurrido por pura suerte, suponiendo que la moneda no est√© trucada (hip√≥tesis nula).
  
  Ahora, si calculamos la probabilidad de que salgan 10 caras seguidas por azar:
  $$\frac{1}{0.5^{10}}$$
  Obtenemos un valor p aproximado de **0,001**.
  
  Si comparamos ese valor con el l√≠mite alfa que normalmente se fija en 0,05, vemos que est√° por debajo, lo que indica una evidencia fuerte contra la hip√≥tesis nula y un resultado ‚Äúestad√≠sticamente significativo‚Äù.
  
  En conclusi√≥n, dado que obtener 10 caras seguidas es algo extremadamente improbable si la moneda no est√° trucada, tenemos razones s√≥lidas para rechazar la idea de que la moneda es normal.
</details>

### üìñ Explica el trasfondo estad√≠stico del poder.
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  El poder estad√≠stico se puede entender como la capacidad de una prueba para detectar un efecto o cambio real cuando este realmente existe, es decir, la probabilidad de rechazar la hip√≥tesis nula cuando dicha hip√≥tesis es falsa. Est√° muy relacionado con el error de tipo II, puesto que el poder estad√≠stico pretende evitar no captar un fen√≥meno que s√≠ est√° ocurriendo.
  
  El poder estad√≠stico se basa en:
  * **El tama√±o de la muestra:** cuantos m√°s datos recolectemos, m√°s poder tendr√° nuestra prueba de detectar lo que est√° pasando.
  * **Tama√±o del efecto (effect size):** la magnitud de la diferencia que queremos detectar. Es m√°s f√°cil detectar un cambio gigante (aumento de 20% en ventas) que uno diminuto.
  * **Nivel de significaci√≥n:** el umbral que establecemos para dar un resultado estad√≠sticamente significativo.
  * **Suposici√≥n previa:** generalmente se apunta a tener un poder del 80%, lo que supone aceptar un 20% de probabilidad de no detectar un efecto real.
  
  La utilidad m√°s com√∫n del poder estad√≠stico es el c√°lculo del tama√±o de la muestra antes de empezar un experimento. Si dise√±amos un experimento sin considerar el poder, corremos el riesgo de invertir tiempo y dinero en una prueba que termine siendo inconcluyente, no porque no haya un efecto, sino porque no ten√≠amos suficientes datos para detectarlo.
</details>

### üìñ Digamos que est√°s comprobando cientos de hip√≥tesis, cada una con un t-test. ¬øQu√© consideraciones deber√≠amos tomar si hacemos esto?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

  Si realizamos cientos de t-test deberemos tener en cuenta los siguientes fen√≥menos:
  * **Error de Tipo I:** si hacemos un solo test solemos aceptar un margen de error del 5%, pero al hacer cientos de pruebas el riesgo de obtener un resultado por azar se acumula, lo que aumenta en gran cantidad la probabilidad de cometer un falso positivo.
  * **Data snooping:** existe un dicho que dice que ‚ÄúSi torturas los datos lo suficiente, tarde o temprano confesar√°n‚Äù. Esto quiere decir que si buscamos patrones en una base de datos haciendo cientos de preguntas distintas sin un plan previo, acabaremos encontrando algo que nos parezca interesante, pero que en realidad es solo ruido estad√≠stico.
  
  Entre las principales medidas que podemos tomar para evitar estos problemas son la **correcci√≥n de Bonferroni** (dividir el nivel de error por el n√∫mero de pruebas a realizar) y el **Holdout Set** (guardar datos de reserva para una comprobaci√≥n en datos nuevos una vez pensamos que hemos encontrado algo).
</details>

### üìñ ¬øEn qu√© consiste el compromiso entre sesgo y varianza (bias-variance trade-off) y c√≥mo influye en el fen√≥meno del sobreajuste (overfitting)?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

Existe un relaci√≥n inversa entre ellos: si intentamos reducir el sesgo (haciendo el modelo m√°s complejo), la varianza tiende a subir autom√°ticamente. Por el contrario, si intentamos que el modelo sea muy estable y tenga poca varianza, probablemente ser√° demasiado simple y aumentar√° el sesgo. 

El fen√≥meno del sobreajuste ocurre cuando perdemos el equilibrio y dejamos que la varianza aumente dr√°sticamente. Esto provoca un modelo ‚Äúdemasiado flexible‚Äù que aprende tan bien los datos de entrenamiento que incluye en su l√≥gica los errores aleatorios y el ruido que no se repetir√°n el futuro. 

De este modo, si miramos los resultados del enternamiento, se acercar√°n mucho al objetivo real pero al presentarle al modelo datos nuevos que nunca haya visto, su rendimiento caer√° dr√°sticamente porque esos datos nuevos no presentan ese ‚Äúruido‚Äù del cual ha aprendido en los datos de entrenamiento. 

Para evitar el sobreajuste, debemos aceptar un poco m√°s de sesgo (modelo algo m√°s simple) a cambio de reducir la varianza, asegurando as√≠ que nuestra m√°quina puede generalizar lo aprendido en situaciones y conjuntos de datos nuevos.
</details>

### üìñ Explica detalladamente qu√© es un valor p (p-value) y por qu√© un resultado estad√≠sticamente significativo no siempre implica una importancia pr√°ctica para el negocio.
<details>
  <summary><b>Ver respuesta üîë</b></summary>

El p - value es la probabilidad de que, aceptando la hip√≥tesis nula, el resultado esperado se de por casualidad. 

Si el p valor es bajo (menor o igual que 0,05) significa que es muy poco probable que el azar sea responsable y por tanto rechazaremos la hip√≥tesis nula y concluiremos que el resultado es ‚Äúestad√≠sticamente significativo‚Äù. Si por el contrario el valor p es mayor a 0,05, significa que lo que observamos entra dentro de lo que el azar podr√≠a poducir normalmente. 

Uno de los aspectos clave del p - value es que solo nos indica si el resultado es debido a un efecto real, pero no indica el tama√±o de ese efecto. Esto supone que aplicar una medida validada por el p - value provoque una diferencia tan peque√±a que no tenga sentido para el negocio.
</details>

### üìñ ¬øQu√© es la multicolinealidad en un modelo de regresi√≥n lineal m√∫ltiple y qu√© impacto tiene sobre la estabilidad y la interpretaci√≥n de los coeficientes de las variables independientes?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

La multicolinealidad es una condici√≥n que ocurre en los modelos estad√≠sticos cuando dos o m√°s de las variables que usas para predecir un resultado est√°n fuertemente relacionadas entre s√≠. 

Cuando existe multicolinealidad, el modelo se vuelve matem√°ticamente inestable, lo que puede provocar que cualquier cambio m√≠nimo en los datos de entrada deriven en cambios dr√°sticos en los resultados del modelo, lo que hace que las conclusiones sean poco fiables. 

El problema m√°s grande es que este fen√≥meno impide saber qu√© variable es la verdadera responsable del resultado, ya que las variables correlacionadas tienden a ‚Äúcancelarse‚Äù entre s√≠ en los c√°lculos. Adem√°s, la multicolinealidad infla el error est√°ndar (mayor inestabilidad), lo que significa que el modelo pierde mucha precisi√≥n al tratar de estimar qu√© tan importante es realmente cada factor.
</details>


### üìñ ¬øQu√© es la multicolinealidad en un modelo de regresi√≥n lineal m√∫ltiple y qu√© impacto tiene sobre la estabilidad y la interpretaci√≥n de los coeficientes de las variables independientes?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

La multicolinealidad es una condici√≥n que ocurre en los modelos estad√≠sticos cuando dos o m√°s de las variables que usas para predecir un resultado est√°n fuertemente relacionadas entre s√≠. 

Cuando existe multicolinealidad, el modelo se vuelve matem√°ticamente inestable, lo que puede provocar que cualquier cambio m√≠nimo en los datos de entrada deriven en cambios dr√°sticos en los resultados del modelo, lo que hace que las conclusiones sean poco fiables. 

El problema m√°s grande es que este fen√≥meno impide saber qu√© variable es la verdadera responsable del resultado, ya que las variables correlacionadas tienden a ‚Äúcancelarse‚Äù entre s√≠ en los c√°lculos. Adem√°s, la multicolinealidad infla el error est√°ndar (mayor inestabilidad), lo que significa que el modelo pierde mucha precisi√≥n al tratar de estimar qu√© tan importante es realmente cada factor.
</details>

### üìñ ¬øPor qu√© la exactitud (accuracy) puede ser una m√©trica enga√±osa cuando se trabaja con un conjunto de datos altamente desbalanceado (como en la detecci√≥n de fraudes o enfermedades raras) y qu√© m√©tricas alternativas (como precisi√≥n, recall o F1-score) proporcionar√≠an una visi√≥n m√°s real del rendimiento del modelo?
<details>
  <summary><b>Ver respuesta üîë</b></summary>

La exactitud es una m√©tica que puede ser muy enga√±osa porque simplemente mide el porcentaje total de aciertos sin distinguir qu√© tipo de casos est√° acertando. En situaciones donde una categor√≠a es mucho m√°s frecuente que la otra, el modelo tiende a ‚Äúignorar‚Äù la clase minoritaria para centrarse en acertar la clase mayoritaria, lo que puede dar una falsa sensaci√≥n de √©xito.

Para evaluar realmente el rendimiento, los cient√≠ficos de datos miran una tabla llamada matriz de confusi√≥n, que separa los aciertos y errores por categor√≠as. De ah√≠, podemos extrar m√©tricas m√°s inteligentes: 

1. Precisi√≥n

Mide la exactitud del modelo cuando hace una predicci√≥n positiva. De todas las veces que el modelo detect√≥ un positivo, ¬øqu√© porcentaje fue cierto?

![precision](https://github.com/Nachoide100/Preguntas-estadistica/blob/2c5f05eafbbc0bdf23122704e2be8cca8f762305/visualizations/Captura%20de%20pantalla%202026-02-06%20192656.png)

2. Recall (Sensibilidad)

Mide la capacidad del modelo para encontrar todos los casos positivos existentes. De todos los casos reales que hab√≠a, ¬øcu√°ntos fue capaz de capturar el modelo?

![recall](https://github.com/Nachoide100/Preguntas-estadistica/blob/2c5f05eafbbc0bdf23122704e2be8cca8f762305/visualizations/Captura%20de%20pantalla%202026-02-06%20192754.png)

3. F1 - Score

Es la media arm√≥nica enter la precisi√≥n y el recall. Se utiliza para obtener un solo n√∫mero que equilibre ambas m√©tricas, siendo especialmente √∫til cuando tienes un conjunto de datos desbalanceado y quieres asegurarte de que tu modelo sea bueno tanto detectando positivos como evitando falsos positivos.

![f1_score](https://github.com/Nachoide100/Preguntas-estadistica/blob/2c5f05eafbbc0bdf23122704e2be8cca8f762305/visualizations/Captura%20de%20pantalla%202026-02-06%20192941.png)

Vemos que existe una estrecha relaci√≥n entre Precisi√≥n y Sensibilidad. El buscar aumentar una o la otra depender√° del contexto en el que nos encontremos. 

</details>

---

## üü° Nivel: Intermedio

---

## üî¥ Nivel: Dif√≠cil

<p align="right">(<a href="#-wiki-de-estad√≠stica-aplicada">Volver arriba ‚¨ÜÔ∏è</a>)</p>


